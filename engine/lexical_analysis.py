import re

from engine.utils import LexTokens, BaseManager


class Scanner(BaseManager):
    """
    Class that performs a lexical analysis of the template.
    """

    def __init__(self, filepath):
        """
        Constructor that initializes the arguments of the object.
        :param filepath: String containing the path of the template file.
        :raise: IOError when there is no file with such path.
        """
        super().__init__(filepath)

    def scan(self):
        """
        Performs the lexical analysis of the template file returning the tokens one by one.
        :return: Tuple (engine.LexTokens, String) containing the type of the token and its contents.
        """
        with open(self._filepath, 'r') as template_file:
            for line in template_file:
                # Remove the \n character at the end of the line
                line = line[:-1]

                line = re.findall(r"{{2}|}{2}|[^ \n{}]*", line)
                # Removes the last empty token generated by the regex.
                line = line[:-1]

                for word in line:
                    if word == '{{':
                        yield LexTokens.INIT_EXPRESSION, None
                    elif word == '}}':
                        yield LexTokens.END_EXPRESSION, None
                    elif word == '#loop':
                        yield LexTokens.INIT_LOOP, None
                    elif word == '/loop':
                        yield LexTokens.END_LOOP, None
                    elif word == "":
                        yield LexTokens.BLANK, " "
                    else:
                        yield LexTokens.VERBATIM, word
                yield LexTokens.EOL, "\n"
